---
layout: post
title: "Final: Ideas and Test"
categories: mlforweb
---

For the final, I wanted to use style transfer to experiment with formatting memes. I have been making memes on instagram in a specific style over the past 2 years. I noticed that some friends that also do this each have their own style for formatting the images and text. I wanted to see if I could train a model for each style of meme. Then, for example, use style transfer to change the formatting of a meme to look like it was made by me.

![alt text](https://raw.githubusercontent.com/jirrian/jirrian.github.io/master/images/mlforweb/examples.jpg)
images used for this test are by [me](https://www.instagram.com/ada.wrong/), [@djinn_kazama](https://www.instagram.com/djinn_kazama/), and [@renaissance__man](https://www.instagram.com/renaissance__man/)

The final result was not that good. Maybe with adjusting settings I can get more of the input images rather than the model?
I would also like to know if I can train a model using multiple images (since I have a lot of memes with the same style) rather than just selecting one. The one I selected to train the model with has green and red accents and I sometimes use other specific colors like blue and magenta.

![alt text](https://raw.githubusercontent.com/jirrian/jirrian.github.io/master/images/mlforweb/test_result.png)
[try it here live](http://blog.jzhong.today/meme-style-transfer/)
[github repo](https://github.com/jirrian/meme-style-transfer)

I understand with my project I'm not really using style transfer for exactly what it was intended for since I'm also using text. I'm just interested in having varied and interesting outputs rather than the output being readable as a meme.
I may have better results with a more complex visual style (if I trained the model on my friend's stuff instead).

My second idea that I didn't get to test is to make a filter using style transfer that makes a user's selfie look like a computer generated graphic. Kind of like sims or IMVU style.
